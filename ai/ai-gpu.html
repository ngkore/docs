<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="The Hidden Army: How AI Training Actually Happens Across Thousands of GPUs" />
<meta property="og:type" content="website" />
<meta property="og:url" content="ai/ai-gpu.html" />
<meta property="og:site_name" content="NgKore" />
<meta property="og:description" content="Understanding the $7 trillion infrastructure race that’s powering the AI revolution When you ask ChatGPT a question or generate an image with DALL-E, you’re witnessing the end result of one of the ..." />
<meta property="og:image" content=".sphinx/_static/tag.png" />
<meta property="og:image:alt" content="NgKore" />
<meta name="description" content="Understanding the $7 trillion infrastructure race that’s powering the AI revolution When you ask ChatGPT a question or generate an image with DALL-E, you’re witnessing the end result of one of the ..." />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="The AI Traffic Cops: How Machine Learning Routes Your Phone Calls in Real-Time" href="route-phone-call.html" /><link rel="prev" title="AI/ML" href="index.html" />

    <link rel="shortcut icon" href="../_static/favicon.png"/><!-- Generated with Sphinx 8.2.3 and Furo 2024.08.06 -->
        <title>The Hidden Army: How AI Training Actually Happens Across Thousands of GPUs - NgKore Docs</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../_static/youtube.css" />
    <link rel="stylesheet" type="text/css" href="../_static/related-links.css" />
    <link rel="stylesheet" type="text/css" href="../_static/terminal-output.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=f84bc4ab" />
    <link rel="stylesheet" type="text/css" href="../_static/header.css?v=23b7cbea" />
    <link rel="stylesheet" type="text/css" href="../_static/github_issue_links.css?v=be107c51" />
    <link rel="stylesheet" type="text/css" href="../_static/furo_colors.css?v=0eedd8e7" />
    
</head>
  <body>
    <header id="header" class="p-navigation">

  <div class="p-navigation__nav" role="menubar">

    <ul class="p-navigation__links" role="menu">

      <li>
        <a class="p-logo" href="https://github.com/ngkore" aria-current="page">
          <img src="../_static/tag.png" alt="Logo" class="p-logo-image">
          <!-- <div class="p-logo-text p-heading--4">NgKore
          </div> -->
        </a>
      </li>


    </ul>
    <!-- Add your website link here -->
    <a href="https://ngkore.org" target="_blank" class="p-header-link">
      NgKore.org
    </a>
  </div>
</header>
   
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">NgKore Docs</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">NgKore Docs</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../kernel-bypass/index.html">Kernel Bypass Mechanisms</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Kernel Bypass Mechanisms</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../kernel-bypass/af_xdp.html">AF_XDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernel-bypass/dpdk.html">DPDK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernel-bypass/sriov.html">SR-IOV</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../oran/index.html">O-RAN</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of O-RAN</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../oran/xfapi-part1.html">Challenges in L1-L2 Interoperability within O-RAN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../oran/xfapi-part2.html">Understanding xFAPI: Bridging L1 and L2 Layers of O-RAN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../oran/xfapi-part3.html">Open RAN (O-RAN) Interoperability with xFAPI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../oran/smo-qoe-prediction.html">QoE Prediction Using AI/ML Framework in Distributed ORAN Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../oran/smo-uav-path-preduction.html">UAV Path Prediction Using AI/ML Framework in Distributed ORAN Architecture</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ebpf/index.html">eBPF</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of eBPF</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../ebpf/ebpf-meets-5g.html">eBPF Meets 5G: Transforming User Plane Function for Next-Gen Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ebpf/hexaebpf.html">HEXAeBPF: The Future of Interoperable eBPF Defined 5G Core (eDC)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ebpf/ebpf.html">eBPF : Unveiling the Future of Computing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ebpf/ebpf-maps.html">The Magic of eBPF Maps: Building a High-Performance Rate Limiter Without Touching User Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ebpf/xdp-ebpf.html">Unlocking Network Performance with XDP and eBPF</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ebpf/ebpf-cuda.html">Inside CUDA: Building eBPF uprobes for GPU Monitoring</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ebpf/ebpf-gpu.html">The Silent Revolution: eBPF Is Hacking Your GPU (For Good)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ebpf/ebpf-monitoring.html">Building an eBPF Process Monitor with Go: A Step-by-Step Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ebpf/ebpf-network-detective.html">eBPF: The Network Detective</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ebpf/ebpf-ssd.html">Your SSD Is About to Get Superpowers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ebpf/l4-lb.html">Load Balancing at Light Speed:</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../5g-operator/index.html">5G Core Operator</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of 5G Core Operator</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../5g-operator/ngkore_operator.html">NgKore Operator</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../l3af/index.html">L3AF</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of L3AF</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../l3af/l3af.html">L3AF Integration with 5G-UPF</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../security/index.html">Networking and Security</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Networking and Security</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../security/tls.html">TLS/SSL Connection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../security/supi.html">Can 5G SUPI Concealment really ensure Forward Secrecy?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../security/ipsec.html">Understanding IPsec: How Internet Security Works</a></li>
<li class="toctree-l2"><a class="reference internal" href="../security/quic.html">QUIC: The Future of Internet Transport</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ntn/index.html">NTN</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of NTN</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../ntn/ntn1.html">Introduction to NTN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ntn/ntn2.html">OAI NTN Part 1: Breaking the Source Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ntn/p1-of-5.html">From Ground to Space: The 5G Revolution Above the Clouds</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ntn/p2-of-5.html">Space Giants: Who’s Building the Internet in the Sky</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ntn/dtn.html">Delay-Tolerant Networks (DTNs): Networking Beyond Earth</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../pqc/index.html">PQC</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of PQC</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../pqc/pqc-intro.html">Introduction To Post-Quantum Cryptography</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pqc/oqs-lib.html">Working of Open Quantum Safe Library</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pqc/quantum-proof-algo.html">Learning with Errors: Quantum-Proof Algorithm</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../5g/index.html">5G Core</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of 5G Core</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../5g/5g-upf.html">5G UPF</a></li>
<li class="toctree-l2"><a class="reference internal" href="../5g/rewrite-upf.html">Rewiring the 5G Data Plane: XDP/eBPF in the Fast Lane of UPF</a></li>
<li class="toctree-l2"><a class="reference internal" href="../5g/os-5g-compare.html">Understanding Open-Source 5G Core Network Evolution in 2025</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">AI/ML</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of AI/ML</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">The Hidden Army: How AI Training Actually Happens Across Thousands of GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="route-phone-call.html">The AI Traffic Cops: How Machine Learning Routes Your Phone Calls in Real-Time</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/ai/ai-gpu.md.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="the-hidden-army-how-ai-training-actually-happens-across-thousands-of-gpus">
<h1>The Hidden Army: How AI Training Actually Happens Across Thousands of GPUs<a class="headerlink" href="#the-hidden-army-how-ai-training-actually-happens-across-thousands-of-gpus" title="Link to this heading">¶</a></h1>
<p><em>Understanding the $7 trillion infrastructure race that’s powering the AI revolution</em></p>
<p>When you ask ChatGPT a question or generate an image with DALL-E, you’re witnessing the end result of one of the most complex computational processes ever created. Behind that simple chat interface lies a “hidden army” of thousands of graphics processing units (GPUs) working in perfect synchronization. Yet despite companies investing trillions of dollars in this infrastructure, most people have no idea how it actually works.</p>
<p>Today, we’re pulling back the curtain on the massive, invisible machinery that makes modern AI possible.</p>
<section id="quick-facts-that-will-blow-your-mind">
<h2>Quick Facts That Will Blow Your Mind<a class="headerlink" href="#quick-facts-that-will-blow-your-mind" title="Link to this heading">¶</a></h2>
<p>Before we dive deep, here are some jaw-dropping facts about modern AI training:</p>
<ul class="simple">
<li><p><strong>Scale</strong>: Modern AI clusters use 10,000 to 100,000+ GPUs working simultaneously</p></li>
<li><p><strong>Power</strong>: Each GPU performs 32 million billion operations per second</p></li>
<li><p><strong>Cost</strong>: Single training runs can cost millions of dollars</p></li>
<li><p><strong>Time</strong>: Training GPT-4 level models takes months even on supercomputers</p></li>
<li><p><strong>Investment</strong>: Companies are spending $10–50 billion on individual AI data centers</p></li>
</ul>
</section>
<section id="the-scale-that-defies-imagination">
<h2>The Scale That Defies Imagination<a class="headerlink" href="#the-scale-that-defies-imagination" title="Link to this heading">¶</a></h2>
<p>To understand the magnitude of modern AI training, let’s start with some numbers that sound like science fiction. The latest AI supercomputers don’t just use a few powerful computers — they coordinate tens of thousands of GPUs simultaneously. Elon Musk’s xAI Colossus cluster, for example, packs 64 GPUs per rack across hundreds of racks, while companies are now building systems that scale to over 100,000 GPUs working as a single, unified brain.</p>
<p>Think about that for a moment. We’re talking about more computing power concentrated in a single facility than entire countries had access to just a decade ago. Each individual GPU in these clusters is roughly equivalent to the processing power of hundreds of traditional computer processors, and they’re all working together on a single problem: teaching an AI system to understand and generate human language, images, or code.</p>
</section>
<section id="why-the-traditional-approach-stopped-working">
<h2>Why The Traditional Approach Stopped Working<a class="headerlink" href="#why-the-traditional-approach-stopped-working" title="Link to this heading">¶</a></h2>
<p>For decades, when we needed more computing power, the solution was simple: build faster processors. This approach, known as “scaling up,” worked well until we hit fundamental physical limits. Modern processors are already built at atomic scales, and making them significantly faster has become increasingly difficult and expensive.</p>
<p>But AI training presents a unique challenge that’s different from traditional computing tasks. Training a large language model like GPT-4 requires processing datasets containing trillions of words and performing mathematical operations on models with hundreds of billions of parameters. No single computer, no matter how powerful, can handle this workload in a reasonable timeframe.</p>
<p>The solution? Instead of building one impossibly powerful computer, we build thousands of moderately powerful ones and teach them to work together. This approach, called “scaling out” or distributed computing, is what enables modern AI training — but it comes with its own set of mind-bending challenges.</p>
</section>
<section id="the-architecture-of-an-ai-supercomputer">
<h2>The Architecture of an AI Supercomputer<a class="headerlink" href="#the-architecture-of-an-ai-supercomputer" title="Link to this heading">¶</a></h2>
<p>Understanding how thousands of GPUs work together requires grasping several interconnected systems working in harmony.</p>
<section id="the-foundation-gpu-clusters">
<h3>The Foundation: GPU Clusters<a class="headerlink" href="#the-foundation-gpu-clusters" title="Link to this heading">¶</a></h3>
<p>At the heart of every AI supercomputer are GPU clusters — groups of graphics processors originally designed for rendering video game graphics but repurposed for AI calculations. Modern systems like NVIDIA’s DGX H100 pack eight of the most powerful GPUs available into a single server, connected through high-speed links called NVLink that allow them to share information almost instantaneously.</p>
<p>Each individual GPU in these systems can perform 32 petaflops of AI calculations — that’s 32 million billion operations per second. When you multiply that by thousands of GPUs, you’re dealing with computational power that borders on the incomprehensible.</p>
</section>
<section id="the-nervous-system-network-infrastructure">
<h3>The Nervous System: Network Infrastructure<a class="headerlink" href="#the-nervous-system-network-infrastructure" title="Link to this heading">¶</a></h3>
<p>The real magic happens in the networking layer that connects all these GPUs. Unlike your home internet connection, these systems require incredibly fast, low-latency networks that can handle massive amounts of data transfer between thousands of nodes simultaneously.</p>
<p>This networking infrastructure is so critical that it often determines the success or failure of the entire system. When training an AI model, the GPUs need to constantly share information about what they’ve learned, coordinate their activities, and synchronize their progress. Any delay or bottleneck in communication can bring the entire system to a crawl.</p>
</section>
<section id="the-coordination-challenge-software-orchestration">
<h3>The Coordination Challenge: Software Orchestration<a class="headerlink" href="#the-coordination-challenge-software-orchestration" title="Link to this heading">¶</a></h3>
<p>Perhaps the most complex aspect of distributed AI training is the software that coordinates everything. Imagine trying to organize 10,000 people to work on a single jigsaw puzzle simultaneously, with each person only able to see a small portion of the overall picture. That’s essentially what the software managing these systems has to do.</p>
<p>The training process typically involves splitting both the AI model and the training data across multiple GPUs. Some GPUs might work on understanding language patterns while others focus on mathematical reasoning. The software has to ensure that all these different pieces of work contribute to improving the overall model, while also handling the inevitable hardware failures and communication delays.</p>
</section>
</section>
<section id="the-hidden-complexities-nobody-talks-about">
<h2>The Hidden Complexities Nobody Talks About<a class="headerlink" href="#the-hidden-complexities-nobody-talks-about" title="Link to this heading">¶</a></h2>
<p>While the technical specifications of these systems are impressive, the real challenges lie in the details that don’t make headlines.</p>
<section id="the-reliability-problem">
<h3>The Reliability Problem<a class="headerlink" href="#the-reliability-problem" title="Link to this heading">¶</a></h3>
<p>When you’re coordinating thousands of individual components, the probability that something will go wrong approaches certainty. In these massive clusters, hardware failures are not occasional problems — they’re daily occurrences. Network connections fail, individual GPUs overheat, power supplies die, and cooling systems struggle to keep up.</p>
<p>The software managing these systems has to be designed to handle these failures gracefully, redistributing work from failed components to healthy ones without losing days or weeks of training progress. This is like trying to keep a 10,000-person orchestra playing in harmony while individual musicians randomly drop out and new ones join in.</p>
</section>
<section id="the-communication-bottleneck">
<h3>The Communication Bottleneck<a class="headerlink" href="#the-communication-bottleneck" title="Link to this heading">¶</a></h3>
<p>As these systems scale larger, communication between GPUs becomes increasingly challenging. Each GPU needs to share what it has learned with thousands of others, creating a communication pattern that can quickly overwhelm even the fastest networks.</p>
<p>Modern systems use sophisticated techniques like gradient compression and communication scheduling to minimize these bottlenecks, but the fundamental challenge remains: the larger the system, the more time the GPUs spend talking to each other instead of actually training the AI model.</p>
</section>
<section id="the-power-and-cooling-challenge">
<h3>The Power and Cooling Challenge<a class="headerlink" href="#the-power-and-cooling-challenge" title="Link to this heading">¶</a></h3>
<p>These systems consume enormous amounts of electricity — a single large AI training cluster can use as much power as a small city. All that electricity turns into heat, requiring massive cooling systems that often consume almost as much power as the computers themselves.</p>
<p>Building the infrastructure to support these power requirements often means working directly with utility companies to ensure adequate electrical supply, and locating facilities near sources of cheap, reliable power — preferably renewable energy to offset the environmental impact.</p>
</section>
</section>
<section id="the-economics-of-the-ai-infrastructure-race">
<h2>The Economics of the AI Infrastructure Race<a class="headerlink" href="#the-economics-of-the-ai-infrastructure-race" title="Link to this heading">¶</a></h2>
<p>The scale of investment in AI infrastructure is staggering. Companies are spending tens of billions of dollars on individual training clusters, with the total global investment in AI infrastructure expected to reach into the trillions over the next decade.</p>
<p>This creates a fascinating economic dynamic. The companies with access to the largest, most efficient training infrastructure have a significant advantage in developing the most capable AI systems. This has led to an arms race where tech giants are racing to build ever-larger clusters, often before they’ve even figured out exactly how they’ll use them.</p>
<p>The stakes are enormous because the company that can train the most capable AI systems fastest will likely dominate multiple industries. This explains why companies like Microsoft, Google, Amazon, and others are willing to make such massive infrastructure investments.</p>
</section>
<section id="whats-coming-next">
<h2>What’s Coming Next<a class="headerlink" href="#whats-coming-next" title="Link to this heading">¶</a></h2>
<section id="the-scale-will-get-even-bigger">
<h3>The Scale Will Get Even Bigger<a class="headerlink" href="#the-scale-will-get-even-bigger" title="Link to this heading">¶</a></h3>
<p><strong>Near-Term Plans:</strong></p>
<ul class="simple">
<li><p>Systems with millions of GPUs in development</p></li>
<li><p>Multi-data center training spanning continents</p></li>
<li><p>Using entire internet as global AI infrastructure</p></li>
<li><p>Quantum-AI hybrid systems on the horizon</p></li>
</ul>
<p><strong>New Technologies:</strong></p>
<ul class="simple">
<li><p>Google’s TPUs and custom AI chips</p></li>
<li><p>Apple’s Neural Engine expansion</p></li>
<li><p>Specialized training processors from startups</p></li>
<li><p>Potential challenge to NVIDIA’s dominance</p></li>
</ul>
</section>
<section id="the-efficiency-revolution">
<h3>The Efficiency Revolution<a class="headerlink" href="#the-efficiency-revolution" title="Link to this heading">¶</a></h3>
<p><strong>What’s Being Developed:</strong></p>
<ul class="simple">
<li><p>More efficient training algorithms</p></li>
<li><p>Better hardware utilization techniques</p></li>
<li><p>Edge computing integration</p></li>
<li><p>Reduced power consumption methods</p></li>
</ul>
<p><strong>The Goals:</strong></p>
<ul class="simple">
<li><p>Make AI training more accessible</p></li>
<li><p>Reduce environmental impact</p></li>
<li><p>Enable smaller players to compete</p></li>
<li><p>Distribute AI capabilities more widely</p></li>
</ul>
</section>
</section>
<section id="key-takeaways">
<h2>Key Takeaways<a class="headerlink" href="#key-takeaways" title="Link to this heading">¶</a></h2>
<p><strong>The Hidden Reality:</strong></p>
<ul class="simple">
<li><p>Every AI interaction you have is powered by thousands of GPUs</p></li>
<li><p>This infrastructure represents humanity’s most complex technological undertaking</p></li>
<li><p>The scale and coordination required defies imagination</p></li>
<li><p>Most people have no idea this complexity exists behind simple AI interfaces</p></li>
</ul>
<p><strong>The Stakes:</strong></p>
<ul class="simple">
<li><p>$7 trillion infrastructure race determining the future</p></li>
<li><p>Companies and nations competing for AI dominance</p></li>
<li><p>Those who master this complexity will shape technology for decades</p></li>
<li><p>Concentration of power in hands of few tech giants</p></li>
</ul>
<p><strong>The Questions We Must Answer:</strong></p>
<ul class="simple">
<li><p>Who should control this infrastructure?</p></li>
<li><p>How do we ensure fair access to AI capabilities?</p></li>
<li><p>What regulations are needed?</p></li>
<li><p>How do we balance innovation with responsibility?</p></li>
</ul>
</section>
<section id="conclusion-the-foundation-of-our-ai-future">
<h2>Conclusion: The Foundation of Our AI Future<a class="headerlink" href="#conclusion-the-foundation-of-our-ai-future" title="Link to this heading">¶</a></h2>
<p>The next time you chat with an AI, remember the hidden army working behind the scenes. Thousands of GPUs, billions in infrastructure, enormous power consumption, and incredible engineering complexity — all to enable that simple conversation.</p>
<p>This infrastructure isn’t just about building faster computers. It’s about building the foundation for human-machine collaboration that will define our future. The companies and nations that master this hidden complexity today will likely determine the trajectory of technology for generations.</p>
<p>The hidden army is already here, working 24/7 in data centers around the world. The question now is: how will we choose to direct its power?</p>
</section>
<section id="references-and-sources">
<h2>References and Sources<a class="headerlink" href="#references-and-sources" title="Link to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p><strong>“Scaling Laws for Neural Language Models”</strong> — OpenAI Research Paper <a class="reference external" href="https://arxiv.org/abs/2001.08361">https://arxiv.org/abs/2001.08361</a></p></li>
<li><p><strong>NVIDIA Data Center GPU Documentation and Specifications</strong> <a class="reference external" href="https://www.nvidia.com/en-us/data-center/">https://www.nvidia.com/en-us/data-center/</a></p></li>
<li><p><strong>Meta’s Research SuperCluster (RSC) Technical Documentation</strong> <a class="reference external" href="https://ai.facebook.com/blog/rsc/">https://ai.facebook.com/blog/rsc/</a></p></li>
<li><p><strong>“Data Center Power Consumption Trends”</strong> — International Energy Agency <a class="reference external" href="https://www.iea.org/reports/data-centres-and-data-transmission-networks">https://www.iea.org/reports/data-centres-and-data-transmission-networks</a></p></li>
<li><p><strong>“AI Training Costs and Environmental Impact”</strong> — MIT Technology Review <a class="reference external" href="https://www.technologyreview.com/">https://www.technologyreview.com/</a></p></li>
</ol>
<p>[1] <a class="reference external" href="https://medium.com/&#64;kcl17/the-hidden-army-how-ai-training-actually-happens-across-thousands-of-gpus-a96db487fac9">https://medium.com/&#64;kcl17/the-hidden-army-how-ai-training-actually-happens-across-thousands-of-gpus-a96db487fac9</a></p>
</section>
</section>

        </article>
      </div>
      <footer>
        
   

<div class="related-pages">
  
  
      
  
  
  
    
</div>
<div style="text-align:center; font-size:0.95em; margin-top:1em;">
  For any query please contact: <a href="mailto:contact@ngkore.org">contact@ngkore.org</a>
</div>
<div class="bottom-of-page">
  <div class="left-details">
    <!--
    <div class="copyright">
        Copyright &#169; 
    </div> -->

    

    <!--<div class="last-updated">
      Last updated on Jul 18, 2025</div> -->

    <!--
    <div class="show-source">
      <a class="muted-link" href="../_sources/ai/ai-gpu.md.txt"
         rel="nofollow">Show source</a>
    </div> -->
  </div>
  <div class="right-details">

    

    <!--  -->

    <!--  -->


    </div>
  </div>
</div>

      </footer>
    </div>
    <aside class="toc-drawer">
      
<div class="toc-sticky toc-scroll">
   
    <div class="toc-title-container">
      <span class="toc-title">
       Contents
      </span>
    </div>
    <div class="toc-tree-container">
      <div class="toc-tree">
        <ul>
<li><a class="reference internal" href="#">The Hidden Army: How AI Training Actually Happens Across Thousands of GPUs</a><ul>
<li><a class="reference internal" href="#quick-facts-that-will-blow-your-mind">Quick Facts That Will Blow Your Mind</a></li>
<li><a class="reference internal" href="#the-scale-that-defies-imagination">The Scale That Defies Imagination</a></li>
<li><a class="reference internal" href="#why-the-traditional-approach-stopped-working">Why The Traditional Approach Stopped Working</a></li>
<li><a class="reference internal" href="#the-architecture-of-an-ai-supercomputer">The Architecture of an AI Supercomputer</a><ul>
<li><a class="reference internal" href="#the-foundation-gpu-clusters">The Foundation: GPU Clusters</a></li>
<li><a class="reference internal" href="#the-nervous-system-network-infrastructure">The Nervous System: Network Infrastructure</a></li>
<li><a class="reference internal" href="#the-coordination-challenge-software-orchestration">The Coordination Challenge: Software Orchestration</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-hidden-complexities-nobody-talks-about">The Hidden Complexities Nobody Talks About</a><ul>
<li><a class="reference internal" href="#the-reliability-problem">The Reliability Problem</a></li>
<li><a class="reference internal" href="#the-communication-bottleneck">The Communication Bottleneck</a></li>
<li><a class="reference internal" href="#the-power-and-cooling-challenge">The Power and Cooling Challenge</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-economics-of-the-ai-infrastructure-race">The Economics of the AI Infrastructure Race</a></li>
<li><a class="reference internal" href="#whats-coming-next">What’s Coming Next</a><ul>
<li><a class="reference internal" href="#the-scale-will-get-even-bigger">The Scale Will Get Even Bigger</a></li>
<li><a class="reference internal" href="#the-efficiency-revolution">The Efficiency Revolution</a></li>
</ul>
</li>
<li><a class="reference internal" href="#key-takeaways">Key Takeaways</a></li>
<li><a class="reference internal" href="#conclusion-the-foundation-of-our-ai-future">Conclusion: The Foundation of Our AI Future</a></li>
<li><a class="reference internal" href="#references-and-sources">References and Sources</a></li>
</ul>
</li>
</ul>

      </div>
    </div>
   
    
  </div>

    </aside>
  </div>
</div><script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../_static/header-nav.js?v=e117ad08"></script>
    
<script>
  const github_url = "https://github.com/ngkore";
</script>
</body>
</html>